# WBSchool-olap-5_task
SPARK

ЗАДАНИЕ

1. Считать данные из вашей Кафки через спарк. Если нужно, залейте немного данных с пегас.
2. Добавить какую-нибудь колонку. Записать в ваш клик в докере.
*Можно через csv импортировать в ваш клик справочник объемов nm_id с пегаса, чтобы оттуда брать объем номенклатуры.
3. Выложить папку с docker-compose файлами для развертывания контейнеров. Должно быть 2 файла: docker-compose.yml, .env.
4. Запушить в свой гит получившийся таск спарк. Не пушить файл с паролями.
5. Выложить в гит скрины с содержимым конечной папки в вашем клике. 
6. Выложить код структуру конечной таблицы в вашем клике.
7. Выложить скрин веб интерфейса вашего спарк.
8. Скрин работы вашего приложения из консоли контейнера.

РЕШЕНИЕ
1. Решение начинается с п.3
2. Решение начинается с п.3
3. docker-compose директории: clickhouse, kafka, spark
4. task Spark
5. Скрин содержимого клика
6. Код, структура конечной таблицы в Clickhouse
7. Скрин Веб интерфейса Spark
8. Скрин работы приложения из консоли
